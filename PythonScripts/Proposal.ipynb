{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于Transformer模型的去批次效应方法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 数据读入"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过Classification()包装函数，读入数据后返回带有聚类标签的干净数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def Classification(filepath):\n",
    "    # 读入 h5ad数据，可以比读入csv.gz更快\n",
    "    adata = sc.read_h5ad(filepath)\n",
    "    # 去除基因表达小于200的细胞\n",
    "    sc.pp.filter_cells(adata, min_genes=200)\n",
    "    # 去除基因表达大于30000的细胞\n",
    "    sc.pp.filter_cells(adata, max_genes=30000)\n",
    "    # 去除小于在3个细胞内表达的基因\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    # 选择线粒体基因\n",
    "    adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
    "    # 线粒体基因质量控制\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    # 去除线粒体基因干扰\n",
    "    adata = adata[adata.obs.n_genes_by_counts < 2500, :]\n",
    "    adata = adata[adata.obs.pct_counts_mt < 5, :]\n",
    "    # 正则化\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    # 筛选高变化高表达基因\n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    # 归一化\n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "    # 表达矩阵保存为DataFrame类\n",
    "    Data = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "    # PCA降维\n",
    "    sc.tl.pca(adata)\n",
    "    # 计算邻居节点信息\n",
    "    sc.pp.neighbors(adata)\n",
    "    # leiden聚类\n",
    "    sc.tl.leiden(adata,resolution=0.95)\n",
    "    # 将leifen聚类信息保存在DataFrame新的一列\n",
    "    Leiden = pd.DataFrame(adata.obs[\"leiden\"], index=adata.obs_names)\n",
    "    Data = pd.concat([Data, Leiden], axis=1, join=\"inner\")\n",
    "    # 返回带有聚类信息的、筛选好的DataFrame数据结构\n",
    "    return Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 距离损失Loss计算"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处计算的loss，表示分类组内与组间距离比值均值\n",
    "$$Loss=\\frac{1}{N}\\sum_{i=1}^N\\frac{||Distance_{In}(X_i)||}{||Distance_{Out}(X_i)||}$$\n",
    "数据使用PyTorch达成GPU加速计算"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本段包含4个定义函数\n",
    "1. Calculate_PCA（Data, N）\n",
    "    - 将读入的数据Data降维成N维\n",
    "2. Calculate_Distance(A, B)\n",
    "    - 计算数据矩阵A和矩阵B之间两两距离矩阵\n",
    "3. Calculate_Normalize(Matrix)\n",
    "    - 将数据举证Matrix根据行的最大最小值归一化\n",
    "4. Calculate_Loss(D1, D2)\n",
    "    - 计算数据矩阵D1和D2之间距离损失函数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "\n",
    "def Calculate_PCA(Data, N):\n",
    "    pca = PCA(n_components=N)\n",
    "    pca_results = pca.fit(Data)\n",
    "    D = pca.fit_transform(Data)\n",
    "    return D\n",
    "\n",
    "def Calculate_Distance(A: torch.Tensor, B: torch.Tensor):\n",
    "    m = A.shape[0]\n",
    "    n = B.shape[0]\n",
    "    D = torch.zeros([m ,n])\n",
    "\n",
    "    M = torch.matmul(A, B.T)\n",
    "    H1 = torch.sum(torch.square(A), axis=1).reshape(1,-1)\n",
    "    H2 = torch.sum(torch.square(B), axis=1).reshape(1,-1)\n",
    "    D = torch.sqrt(-2*M + H2 + H1.T)\n",
    "    return D\n",
    "\n",
    "def Calculate_Normalize(Matrix):\n",
    "    # Normalize\n",
    "    for i, index in enumerate(range(Matrix.shape[0])):\n",
    "        Line = Matrix[index,:]\n",
    "        Min = torch.min(Line)\n",
    "        Max = torch.max(Line)\n",
    "        Matrix[index,:] = (Line - Min) / (Max-Min)\n",
    "    return Matrix\n",
    "\n",
    "\n",
    "def Calculate_Loss(D1, D2):\n",
    "    Distance_Matrix = Calculate_Distance(D1, D2)\n",
    "    Distance_Matrix = Calculate_Normalize(Distance_Matrix)\n",
    "    Leiden1 = torch.FloatTensor(list(map(int, Data1[\"leiden\"].to_list()))).cuda().reshape(-1,1)\n",
    "    Distance_Matrix = torch.cat((Distance_Matrix, Leiden1), 1)\n",
    "\n",
    "    i_max = Distance_Matrix.shape[0] - 1\n",
    "    j_max = Distance_Matrix.shape[1] - 1\n",
    "    Loss_list = torch.zeros([j_max+1]).cuda()\n",
    "    Distance_Min_Index = torch.argmin(Distance_Matrix[:-1,:],dim=0)\n",
    "\n",
    "    for i,Index in enumerate(Distance_Min_Index):\n",
    "        Cluster1 = Distance_Matrix[Index, -1]\n",
    "        Mask1 = (Distance_Matrix[:,-1] == Cluster1)[:-1]\n",
    "        Distance_List = Distance_Matrix[:-1,i]\n",
    "        Distance_In_Group = torch.mean(Distance_List[Mask1])\n",
    "        Distance_Out_Group = torch.mean(Distance_List[Mask1 == False])\n",
    "        Loss_list[i] = Distance_In_Group/Distance_Out_Group\n",
    "    return torch.tensor(torch.sum(Loss_list), requires_grad=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 结果散点图生成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将输出的两个样本在PCA上降维后的数据生成散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def Plot_Tsne(PCA1, PCA2, seed=42):\n",
    "    tsne1 = TSNE(n_components=2, init='pca', random_state=seed)\n",
    "    result1 = tsne1.fit_transform(PCA1)\n",
    "    tsne2 = TSNE(n_components=2, init='pca', random_state=seed)\n",
    "    result2 = tsne2.fit_transform(PCA2)\n",
    "\n",
    "    plt.scatter(result1[:,0],result1[:,1], color=\"hotpink\", s=1)\n",
    "    plt.scatter(result2[:,0],result2[:,1], color=\"#88c999\", s=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 深度学习模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransBE(nn.Module):\n",
    "    def __init__(self, Dim=128, header=8) -> None:\n",
    "        super(TransBE, self).__init__()\n",
    "        # 先将读入的 1 x 50 的数据经过一个Linear层生成 128 x 50的数据\n",
    "        self.linear_layer1 = nn.Linear(1,Dim)\n",
    "        self.relu_layer1 = nn.ReLU()\n",
    "        # self.drop_layer1 = nn.Dropout(0.1) 不知道要不要加，加载哪里\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=Dim, nhead=header)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=Dim , nhead=header)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=6)\n",
    "        self.linear_layer2 = nn.Linear(Dim, 1)\n",
    "        self.relu_layer2 = nn.ReLU()\n",
    "    def forward(self, data):\n",
    "        src = self.relu_layer1(self.linear_layer1(data))\n",
    "        mid = self.transformer_encoder(src)\n",
    "        out = self.transformer_decoder(src, mid)\n",
    "        out = self.relu_layer2(self.linear_layer2(out))\n",
    "        \n",
    "        return mid, out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 实际运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "torch.set_printoptions(precision=10)\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Dim = 16\n",
    "PCA_Size = 50\n",
    "Batch_Size = 32\n",
    "alpha = 0.8\n",
    "seed = 1\n",
    "Max_No_Improve_Steps = 500\n",
    "\n",
    "if os.path.exists(\"../Figures/Figures_seed\"+str(seed)):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(\"../Figures/Figures_seed\"+str(seed))\n",
    "\n",
    "lossfile = open(\"../Figures/Figures_seed\"+str(seed)+\"/LossFile.csv\", \"a\")\n",
    "\n",
    "def Setup_seed(x):\n",
    "    torch.manual_seed(x)\n",
    "    torch.cuda.manual_seed(x)\n",
    "    np.random.seed(x)\n",
    "\n",
    "time0 = time.time()\n",
    "Setup_seed(seed)\n",
    "print(\"Step 1: \", end=\"\")\n",
    "Data1, Data2 = Classification(\"../Data/Sample1.h5ad\"), Classification(\"../Data/Sample2.h5ad\")\n",
    "Keys = list(set(Data1.columns) & set(Data2.columns))\n",
    "Data1, Data2 = Data1[Keys], Data2[Keys]\n",
    "Data1, Data2 = Data1.sort_values(\"leiden\"), Data2.sort_values(\"leiden\")\n",
    "time1 = time.time()\n",
    "print(\"%.2f s\"%(time1-time0))\n",
    "\n",
    "print(\"Step 2: \", end=\"\")\n",
    "Data_All = pd.concat([Data1.drop([\"leiden\"], axis=1), Data2.drop([\"leiden\"], axis=1)])\n",
    "Data_All = Calculate_PCA(Data_All, N=PCA_Size)\n",
    "D1 = torch.FloatTensor(Data_All[0:Data1.shape[0], :]).cuda()\n",
    "D2 = torch.FloatTensor(Data_All[Data1.shape[0]:, :]).cuda()\n",
    "time2 = time.time()\n",
    "print(\"%.2f s\"%(time2-time1))\n",
    "\n",
    "print(\"Step 3: \", end=\"\")\n",
    "dataloader = DataLoader(TensorDataset(D2), batch_size=Batch_Size, shuffle=True)\n",
    "model = TransBE(Dim=16, header=4).cuda()\n",
    "#model = torch.load(\"../Model/Model_v0.0\")\n",
    "criteria = nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "time3 = time.time()\n",
    "print(\"%.2f s\"%(time3-time2))\n",
    "\n",
    "print(\"START!\")\n",
    "Loss_Min = 100000\n",
    "No_Improve_Steps = 0\n",
    "for epoch in range(10000):\n",
    "    Total_Loss = 0\n",
    "    D2_remove_batch = torch.tensor([]).cuda()\n",
    "    for step, data in enumerate(tqdm(dataloader, leave=False)):\n",
    "        optimizer.zero_grad()\n",
    "        ipt = data[0].unsqueeze(2)\n",
    "        mid, tgt = model(ipt)\n",
    "        loss1 = criteria(ipt.contiguous().view(-1, ipt.size(-1)), tgt.contiguous().view(-1, tgt.size(-1)))/Batch_Size\n",
    "        loss2 = Calculate_Loss(D1, torch.squeeze(tgt, 2))/Batch_Size\n",
    "        loss = alpha*loss1+(1-alpha)*loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Total_Loss += loss\n",
    "        D2_remove_batch = torch.cat((D2_remove_batch, tgt.squeeze(2)), 0)\n",
    "    \n",
    "    if Total_Loss <= Loss_Min:\n",
    "        print(\"Epoch {:5d} | Loss = {:.5f}\".format(epoch+1, Total_Loss))\n",
    "        Loss_Min = Total_Loss\n",
    "        No_Improve_Steps = 0\n",
    "        torch.save(model, \"../Model/Model_v0.0\")\n",
    "        print(\"%5d, %.5f\"%(epoch+1, Total_Loss), file=lossfile)\n",
    "        lossfile.flush()\n",
    "        Plot_Tsne(D1.cpu(), D2_remove_batch.cpu().detach(), \"../Figures/Figures_seed{}/Figures_TSNE_{}.png\".format(str(seed),str(epoch+1)))\n",
    "    else:\n",
    "        No_Improve_Steps += 1\n",
    "    \n",
    "    if No_Improve_Steps == Max_No_Improve_Steps:\n",
    "        print(\"Stop because no improve of loss for {} steps\".format(Max_No_Improve_Steps))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
